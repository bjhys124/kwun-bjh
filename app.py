import streamlit as st
from file_parser import parse_text_to_dataframe, parse_csv_to_dataframe
from tax_calculator import calculate_tax
from warning_generator import generate_warnings
from gpt_feedback import get_gpt_feedback

# Streamlit UI ì„¤ì •
st.title("ì„¸ë¬´ GPT ì±—ë´‡ + ìë™ ê²½ê³  + ì„¸ê¸ˆ ê³„ì‚° + ë¦¬í¬íŠ¸ ì €ì¥")

uploaded_file = st.file_uploader("ì¥ë¶€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (.txt ë˜ëŠ” .csv)", type=["txt", "csv"])
question = st.text_input("ì„¸ë¬´ ê´€ë ¨ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ì´ë²ˆ ë‹¬ ì§€ì¶œì€ ì ì ˆí•œê°€ìš”?)")

if uploaded_file:
    if uploaded_file.type == "text/csv":
        df = parse_csv_to_dataframe(uploaded_file)
    else:
        df = parse_text_to_dataframe(uploaded_file)

    st.subheader("ğŸ“‹ ì›ë³¸ ì¥ë¶€ ë°ì´í„°")
    st.dataframe(df)

    with st.spinner("ğŸ“¡ GPT ë¶„ì„ ì¤‘..."):
        warnings = generate_warnings(df)
        summary = df.groupby("ë¶„ë¥˜")["ê¸ˆì•¡"].sum().reset_index()
        vat, income_tax = calculate_tax(df)

        gpt_feedback = get_gpt_feedback(summary, vat, income_tax)

    # ê²½ê³  ë©”ì‹œì§€ ì¶œë ¥
    if warnings:
        st.subheader("âš  ìë™ ê²½ê³  ë©”ì‹œì§€")
        for w in warnings:
            st.write(w)
    else:
        st.success("âœ… ìœ„í—˜ ê²½ê³ ëŠ” ì—†ìŠµë‹ˆë‹¤! ì§€ì¶œì´ ì ì ˆí•´ìš”.")

    # ì„¸ê¸ˆ ê³„ì‚° ê²°ê³¼ ì¶œë ¥
    st.subheader("ğŸ“Š ì„¸ê¸ˆ ìš”ì•½")
    st.write(f"ğŸ“Œ ì˜ˆìƒ ë¶€ê°€ì„¸: ì•½ {vat:,}ì›")
    st.write(f"ğŸ’° ì˜ˆìƒ ì¢…í•©ì†Œë“ì„¸: ì•½ {income_tax:,}ì›")

    # GPT í”¼ë“œë°± ì¶œë ¥
    st.subheader("ğŸ§  GPT ì„¸ë¬´ì‚¬ í”¼ë“œë°±")
    st.write(gpt_feedback)

    # ì„¸ë¬´ ê´€ë ¨ ì§ˆë¬¸ ì‘ë‹µ ì²˜ë¦¬
    if question:
        user_question_prompt = f"ì‚¬ìš©ì ì§ˆë¬¸: {question}"

        followup_response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ì „ë¬¸ ì„¸ë¬´ì‚¬ AIì•¼. ì•„ë˜ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì¥ë¶€ ê¸°ë°˜ìœ¼ë¡œ ì •í™•íˆ ë‹µí•´ì¤˜."},
                {"role": "user", "content": user_question_prompt}
            ],
            temperature=0.5
        )

        st.subheader("ğŸ’¬ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€")
        st.write(followup_response.choices[0].message.content.strip())
