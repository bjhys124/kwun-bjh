import streamlit as st
import pandas as pd
import os
from io import StringIO
from dotenv import load_dotenv
from openai import OpenAI
from datetime import datetime

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
dotenv_path = ".env"
if os.path.exists(dotenv_path):
    load_dotenv(dotenv_path)

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# í…ìŠ¤íŠ¸ íŒŒì¼ íŒŒì‹± í•¨ìˆ˜
def parse_text_to_dataframe(uploaded_file):
    data = []
    for line in uploaded_file.getvalue().decode("utf-8").splitlines():
        parts = [x.strip() for x in line.strip().split("|")]
        if len(parts) == 4:
            date, desc, amount, category = parts
            data.append({"ë‚ ì§œ": date, "ë‚´ìš©": desc, "ê¸ˆì•¡": int(amount), "ë¶„ë¥˜": category})
    return pd.DataFrame(data)

# GPT í˜¸ì¶œ í•¨ìˆ˜ (ì§ˆë¬¸ + ì›”ë§ í”¼ë“œë°± í¬í•¨)
def answer_with_feedback(question, df):
    now_month = datetime.now().strftime("%Y-%m")
    last_feedback_month = st.session_state.get("last_feedback_month")

    summary = summarize_ledger(df)
    vat, income_tax = calculate_tax(df)
    monthly_avg_income = calculate_monthly_avg_income(df)
    warnings = generate_warnings(df)

    content = f"ì‚¬ìš©ì ì§ˆë¬¸: {question}\n\n"
    content += "ì´ë²ˆ ë‹¬(ìë™ ê°ì§€) ì¥ë¶€ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤:\n"
    for _, row in summary.iterrows():
        content += f"- {row['í•­ëª©']}: {int(row['ì´ì•¡'])}ì›\n"
    content += f"\nì›” í‰ê·  ë§¤ì¶œì•¡: ì•½ {monthly_avg_income:,}ì›\n"
    content += f"ì˜ˆìƒ ë¶€ê°€ì„¸: ì•½ {vat:,}ì›\n"
    content += f"ì˜ˆìƒ ì¢…í•©ì†Œë“ì„¸: ì•½ {income_tax:,}ì›\n"
    if warnings:
        content += "\nê²½ê³  í•­ëª©:\n"
        for w in warnings:
            content += f"- {w}\n"

    if last_feedback_month != now_month:
        st.session_state["last_feedback_month"] = now_month
        include_feedback = True
    else:
        include_feedback = False

    system_prompt = """
    ë„ˆëŠ” ì „ë¬¸ ì„¸ë¬´ì‚¬ AIì•¼. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€ì„ ì£¼ë©´ì„œ, ì¶”ê°€ë¡œ ì´ë²ˆ ë‹¬ ìš”ì•½ í”¼ë“œë°±ë„ í¬í•¨í•´ì¤˜.
    ë‹¨, ì›”ë§ í”¼ë“œë°±ì€ í•œ ë‹¬ì— í•œ ë²ˆë§Œ í¬í•¨í•˜ê³ , ì´í›„ ì§ˆë¬¸ì—ëŠ” ìƒëµí•´ë„ ë¼.
    """

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": content}
    ]

    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=messages,
        temperature=0.5
    )
    return response.choices[0].message.content

# Streamlit UI
st.title("ğŸ¤– ì„¸ë¬´ì‚¬ GPT ì±—ë´‡ + ì›”ë§ í”¼ë“œë°±")

# ì¥ë¶€ íŒŒì¼ ì—…ë¡œë“œ
uploaded_file = st.file_uploader(".txt í˜•ì‹ì˜ ì¥ë¶€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type="txt")

# ì§ˆë¬¸ ì…ë ¥ì°½
question = st.text_input("ì„¸ë¬´ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ì´ë²ˆ ë‹¬ ì–´ë• ë‚˜ìš”?)")

if uploaded_file is not None:
    df = parse_text_to_dataframe(uploaded_file)
    st.subheader("ğŸ“‹ ì›ë³¸ ì¥ë¶€ ë°ì´í„°")
    st.dataframe(df)

    if question:
        with st.spinner("AI ì„¸ë¬´ì‚¬ ë‹µë³€ ìƒì„± ì¤‘..."):
            answer = answer_with_feedback(question, df)
            st.subheader("ğŸ¤– ì±—ë´‡ ì‘ë‹µ")
            st.write(answer)
else:
    st.info("ì¥ë¶€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ GPT ë¶„ì„ì´ ê°€ëŠ¥í•´ìš”. ìœ„ì— .txt íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”!")
